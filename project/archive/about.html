<!DOCTYPE html>
<html lang="ko">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Image-2-Text-2-Sound</title>
    <meta name="description" content="이미지-2-텍스트-2-사운드">
    <meta name="keywords" content="ITS, 감각 언어로 번역하기, 감각의 재구성, 이미지, 텍스트, 사운드, 변환">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css">
    <link rel="stylesheet" type="text/css" href="assets/css/about.css">
  </head>
  <body>
    <div class="cards">
      <div>
        <h1>감각 언어로 번역하기<br>
        Image-2-Text-2-Sound</h1>
      </div>

      <div>
        <p>문자 언어는 그 언어를 공유하는 집단의 약속된 사회적 기호체계이다. 그렇기에 서로 다른 언어를 사용하는 사람들은 약속된 기호에 관한 학습 없이는 서로의 사고를 이해하고 생각을 공유하는 데 제한을 겪게 된다. 하지만 감각이라는 언어는 문자 언어에 비해 더 포괄적이다. 감각은 사회적 기호체계가 아니라 ‘문화적 기호체계’이기 때문이다.</p>

        <p>감각 언어는 문자 기호를 공유하지 않는 서로 다른 사회나 국가에서도 동일한 또는 유사한 문화 기호 공유를 가능하게 한다. 그리고 이는 인간이라면 누구나 느낄 수 있는 가장 원초적인 물리적 자극 경험에 의한 기호부터 특정 문화를 공유하는 집단이 공감할 수 있는 기호까지 그 폭 또한 매우 넓다. 이처럼 감각 언어에는 문자 언어의 사회성과 자의성으로부터 벗어날 수 있게 하는 강력한 힘이 있다.</p>

        <p>감각 언어로 번역하기(ITS)는 감각이라는 문화적 기호체계의 확장 가능성에 대해 탐구한 프로젝트이다. 대상을 단순히 사회적 기호체계로 해석하여 문자로 전달하는 것을 넘어, 대상 속 존재하는 감각 경험을 아카이브 함으로써 ‘자국’을 만들고 수집된 자국들을 결합하여 문화적 기호체계로 ‘흔적’을 만들어 낸다. 이를 위해 오브제, 관계, 배경, 구도를 바탕으로 풍부한 내러티브를 만들어 낼 수 있는 호퍼(Edward Hopper)의 작품을 대상으로 선정한다. 각 작품에 ITS (Image-2-Text-2-Sound) 프로세스를 활용하여, 일시적인 시공간 속에 녹아 있는 감각 경험을 이미지, 텍스트, 사운드의 방식으로 아카이브하고 이들을 재구성하여 감각 언어로 번역한다.</p>
        <br><br>
        <details>
          <summary>1. Image ...</summary>
          <p>작가는 시공간의 일부를 포착하여 이미지를 제공한다. 그렇기에 그 속을 면밀히 살펴보면 오브제, 관계, 배경, 구도 등을 통해 시간의 흐름과 풍부한 내러티브를 유추해 볼 수 있다. 작업자는 특히 호퍼(Edward Hopper)의 작품이 그러한 특성을 지닌다고 생각했으며, 그의 작품 중 풍부한 사운드와 내러티브가 느껴지는 이미지를 선정하여 감각 경험을 아카이브 한다.</p>
        </details>
        <details>
          <summary>2. Text ...</summary>
          <p>선정한 이미지를 사운드로 변환하기 위해 감각 경험에 대한 텍스트를 작성한다. 텍스트는 두 종류로 나뉘며, (1) 내러티브 텍스트(Narrative Text)에서는 전체적인 분위기를, (2) 디스크립션 텍스트(Description Text)에서는 오브제 또는 인물에 대한 묘사분석을 작성한다. 이미지 속의 오브제, 관계, 배경, 구도를 고려하여 추출된 텍스트는 이미지 너머의 시간성과 공간성을 묘사하며, 멈춰있는 일시적 이미지를 연속적 시간성을 지닌 사운드로 번역할 수 있는 기틀을 마련한다.</p>
        </details> 
        <details>
          <summary>3. Sound ...</summary>
          <p>이미지에서 추출된 텍스트를 바탕으로 내러티브 사운드와 디스크립션 사운드를 추출한다. (1) 내러티브 사운드(Narrative Sound)는 내러티브 텍스트를 통해 추출한 작품의 전체적 분위기를 표현하는 음원이며, (2) 디스크립션 사운드(Description Sound)는 묘사분석 텍스트를 통해 선정한 오브젝트가 낼 수 있는 여러 소리를 중첩하여 표현한 음원이다. 각각의 음원을 추출한 후 하나의 사운드로 중첩시킨다.</p>
        </details>  
      </div>
      <a href="archive.html" target="_self">
        <div class="move">
          <h2>archive</h2>
        </div>
      </a>
    </div>
  </body>
</html>